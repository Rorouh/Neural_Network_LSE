{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# üéØ Entrenamiento LSE con Visualizaciones\n",
        "\n",
        "Notebook para entrenar modelo T5 de traducci√≥n **Espa√±ol ‚Üí LSE** con gr√°ficas en tiempo real.\n",
        "\n",
        "## üìã Contenido:\n",
        "1. Instalaci√≥n de dependencias\n",
        "2. Imports y configuraci√≥n\n",
        "3. Clase de visualizaci√≥n en tiempo real\n",
        "4. Funciones de carga de datos\n",
        "5. Entrenamiento\n",
        "6. Evaluaci√≥n y ejemplos"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {},
      "outputs": [],
      "source": [
        "# üì¶ Instalaci√≥n de dependencias (ejecuta solo la primera vez)\n",
        "!pip install matplotlib seaborn plotly ipywidgets pandas transformers datasets pyyaml -q"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úÖ Imports completados\n"
          ]
        }
      ],
      "source": [
        "# Imports b√°sicos\n",
        "import os\n",
        "import json\n",
        "import yaml\n",
        "from pathlib import Path\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from IPython.display import display, clear_output\n",
        "import plotly.graph_objects as go\n",
        "from plotly.subplots import make_subplots\n",
        "\n",
        "from datasets import Dataset, DatasetDict\n",
        "from transformers import (\n",
        "    AutoTokenizer, \n",
        "    AutoModelForSeq2SeqLM,\n",
        "    DataCollatorForSeq2Seq, \n",
        "    TrainingArguments, \n",
        "    Trainer,\n",
        "    TrainerCallback\n",
        ")\n",
        "\n",
        "# Configuraci√≥n de estilo\n",
        "sns.set_style(\"whitegrid\")\n",
        "plt.rcParams['figure.figsize'] = (14, 6)\n",
        "plt.rcParams['font.size'] = 10\n",
        "\n",
        "print(\"‚úÖ Imports completados\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úÖ Clase LivePlotCallback creada\n"
          ]
        }
      ],
      "source": [
        "class LivePlotCallback(TrainerCallback):\n",
        "    \"\"\"Callback para visualizar m√©tricas en tiempo real\"\"\"\n",
        "    \n",
        "    def __init__(self):\n",
        "        self.train_losses = []\n",
        "        self.eval_losses = []\n",
        "        self.learning_rates = []\n",
        "        self.grad_norms = []\n",
        "        self.epochs = []\n",
        "        self.steps = []\n",
        "        \n",
        "    def on_log(self, args, state, control, logs=None, **kwargs):\n",
        "        if logs is not None:\n",
        "            if 'loss' in logs:\n",
        "                self.train_losses.append(logs['loss'])\n",
        "                self.steps.append(state.global_step)\n",
        "                \n",
        "            if 'learning_rate' in logs:\n",
        "                self.learning_rates.append(logs['learning_rate'])\n",
        "                \n",
        "            if 'grad_norm' in logs:\n",
        "                self.grad_norms.append(logs['grad_norm'])\n",
        "                \n",
        "            if 'epoch' in logs:\n",
        "                self.epochs.append(logs['epoch'])\n",
        "            \n",
        "            if state.global_step % 50 == 0 and len(self.train_losses) > 1:\n",
        "                self.plot_metrics()\n",
        "    \n",
        "    def on_evaluate(self, args, state, control, metrics=None, **kwargs):\n",
        "        if metrics and 'eval_loss' in metrics:\n",
        "            self.eval_losses.append({\n",
        "                'step': state.global_step,\n",
        "                'epoch': state.epoch,\n",
        "                'loss': metrics['eval_loss']\n",
        "            })\n",
        "            self.plot_metrics()\n",
        "    \n",
        "    def plot_metrics(self):\n",
        "        clear_output(wait=True)\n",
        "        \n",
        "        fig, axes = plt.subplots(2, 2, figsize=(16, 10))\n",
        "        \n",
        "        # Loss\n",
        "        if len(self.train_losses) > 0:\n",
        "            axes[0, 0].plot(self.steps, self.train_losses, 'b-', linewidth=2, label='Train Loss')\n",
        "            \n",
        "            if len(self.eval_losses) > 0:\n",
        "                eval_steps = [e['step'] for e in self.eval_losses]\n",
        "                eval_vals = [e['loss'] for e in self.eval_losses]\n",
        "                axes[0, 0].plot(eval_steps, eval_vals, 'ro-', linewidth=2, \n",
        "                              markersize=8, label='Validation Loss')\n",
        "            \n",
        "            axes[0, 0].set_xlabel('Steps', fontsize=12)\n",
        "            axes[0, 0].set_ylabel('Loss', fontsize=12)\n",
        "            axes[0, 0].set_title('üìâ Loss durante el entrenamiento', fontsize=14, fontweight='bold')\n",
        "            axes[0, 0].legend(loc='upper right')\n",
        "            axes[0, 0].grid(True, alpha=0.3)\n",
        "            \n",
        "            current_loss = self.train_losses[-1]\n",
        "            axes[0, 0].text(0.02, 0.98, f'Loss actual: {current_loss:.4f}',\n",
        "                          transform=axes[0, 0].transAxes, \n",
        "                          verticalalignment='top',\n",
        "                          bbox=dict(boxstyle='round', facecolor='wheat', alpha=0.5))\n",
        "        \n",
        "        # Learning Rate\n",
        "        if len(self.learning_rates) > 0:\n",
        "            axes[0, 1].plot(self.steps, self.learning_rates, 'g-', linewidth=2)\n",
        "            axes[0, 1].set_xlabel('Steps', fontsize=12)\n",
        "            axes[0, 1].set_ylabel('Learning Rate', fontsize=12)\n",
        "            axes[0, 1].set_title('üìä Learning Rate Schedule', fontsize=14, fontweight='bold')\n",
        "            axes[0, 1].grid(True, alpha=0.3)\n",
        "            axes[0, 1].ticklabel_format(style='scientific', axis='y', scilimits=(0,0))\n",
        "        \n",
        "        # Gradient Norm\n",
        "        if len(self.grad_norms) > 0:\n",
        "            axes[1, 0].plot(self.steps, self.grad_norms, 'purple', linewidth=2)\n",
        "            axes[1, 0].set_xlabel('Steps', fontsize=12)\n",
        "            axes[1, 0].set_ylabel('Gradient Norm', fontsize=12)\n",
        "            axes[1, 0].set_title('üéØ Gradient Norm', fontsize=14, fontweight='bold')\n",
        "            axes[1, 0].grid(True, alpha=0.3)\n",
        "            \n",
        "            if max(self.grad_norms) > 10:\n",
        "                axes[1, 0].axhline(y=10, color='r', linestyle='--', \n",
        "                                  label='Umbral de alerta', linewidth=2)\n",
        "                axes[1, 0].legend()\n",
        "        \n",
        "        # Resumen\n",
        "        axes[1, 1].axis('off')\n",
        "        \n",
        "        if len(self.train_losses) > 0:\n",
        "            stats_text = f\"\"\"\n",
        "            üìä RESUMEN DEL ENTRENAMIENTO\n",
        "            ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê\n",
        "            \n",
        "            ‚úì Steps: {self.steps[-1] if self.steps else 0}\n",
        "            ‚úì √âpoca: {self.epochs[-1]:.2f if self.epochs else 0}\n",
        "            \n",
        "            üìâ Loss:\n",
        "               ‚Ä¢ Inicial: {self.train_losses[0]:.4f}\n",
        "               ‚Ä¢ Actual: {self.train_losses[-1]:.4f}\n",
        "               ‚Ä¢ Reducci√≥n: {((self.train_losses[0] - self.train_losses[-1]) / self.train_losses[0] * 100):.1f}%\n",
        "            \n",
        "            üéØ Gradiente:\n",
        "               ‚Ä¢ Promedio: {np.mean(self.grad_norms[-10:]) if len(self.grad_norms) >= 10 else 0:.4f}\n",
        "               ‚Ä¢ M√°ximo: {max(self.grad_norms) if self.grad_norms else 0:.4f}\n",
        "            \"\"\"\n",
        "            \n",
        "            if len(self.eval_losses) > 0:\n",
        "                last_eval = self.eval_losses[-1]['loss']\n",
        "                stats_text += f\"\\n            üîç Val Loss: {last_eval:.4f}\"\n",
        "            \n",
        "            axes[1, 1].text(0.1, 0.9, stats_text, \n",
        "                          transform=axes[1, 1].transAxes,\n",
        "                          fontsize=11,\n",
        "                          verticalalignment='top',\n",
        "                          fontfamily='monospace',\n",
        "                          bbox=dict(boxstyle='round', facecolor='lightblue', alpha=0.3))\n",
        "        \n",
        "        plt.tight_layout()\n",
        "        plt.show()\n",
        "    \n",
        "    def save_final_report(self, output_dir):\n",
        "        os.makedirs(output_dir, exist_ok=True)\n",
        "        \n",
        "        df = pd.DataFrame({\n",
        "            'step': self.steps,\n",
        "            'loss': self.train_losses,\n",
        "            'learning_rate': self.learning_rates[:len(self.steps)],\n",
        "            'grad_norm': self.grad_norms[:len(self.steps)],\n",
        "            'epoch': self.epochs[:len(self.steps)]\n",
        "        })\n",
        "        df.to_csv(f\"{output_dir}/training_metrics.csv\", index=False)\n",
        "        \n",
        "        fig = make_subplots(\n",
        "            rows=2, cols=2,\n",
        "            subplot_titles=('Loss', 'Learning Rate', 'Gradient Norm', 'Train vs Val')\n",
        "        )\n",
        "        \n",
        "        fig.add_trace(\n",
        "            go.Scatter(x=self.steps, y=self.train_losses, \n",
        "                      name='Train Loss', line=dict(color='blue', width=2)),\n",
        "            row=1, col=1\n",
        "        )\n",
        "        \n",
        "        if len(self.eval_losses) > 0:\n",
        "            eval_steps = [e['step'] for e in self.eval_losses]\n",
        "            eval_vals = [e['loss'] for e in self.eval_losses]\n",
        "            \n",
        "            fig.add_trace(\n",
        "                go.Scatter(x=eval_steps, y=eval_vals,\n",
        "                          name='Val Loss', mode='lines+markers',\n",
        "                          line=dict(color='red', width=2)),\n",
        "                row=2, col=2\n",
        "            )\n",
        "        \n",
        "        fig.update_layout(height=800, title_text=\"Reporte de Entrenamiento LSE\")\n",
        "        fig.write_html(f\"{output_dir}/training_report.html\")\n",
        "        \n",
        "        print(f\"‚úÖ Reporte: {output_dir}/training_report.html\")\n",
        "        print(f\"‚úÖ M√©tricas: {output_dir}/training_metrics.csv\")\n",
        "\n",
        "print(\"‚úÖ Clase LivePlotCallback creada\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úÖ Funciones de carga creadas\n"
          ]
        }
      ],
      "source": [
        "def load_jsonl(path):\n",
        "    rows = []\n",
        "    with open(path, \"r\", encoding=\"utf-8\") as f:\n",
        "        for line in f:\n",
        "            if line.strip():\n",
        "                rows.append(json.loads(line))\n",
        "    return rows\n",
        "\n",
        "def build_hf_dataset(train_path, dev_path, test_path):\n",
        "    train = load_jsonl(train_path)\n",
        "    dev = load_jsonl(dev_path)\n",
        "    test = load_jsonl(test_path)\n",
        "    \n",
        "    ds_train = Dataset.from_dict({\"src\": [x[\"src\"] for x in train], \"tgt\": [x[\"tgt\"] for x in train]})\n",
        "    ds_dev = Dataset.from_dict({\"src\": [x[\"src\"] for x in dev], \"tgt\": [x[\"tgt\"] for x in dev]})\n",
        "    ds_test = Dataset.from_dict({\"src\": [x[\"src\"] for x in test], \"tgt\": [x[\"tgt\"] for x in test]})\n",
        "    \n",
        "    return DatasetDict(train=ds_train, validation=ds_dev, test=ds_test)\n",
        "\n",
        "print(\"‚úÖ Funciones de carga creadas\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úÖ Funci√≥n de entrenamiento creada\n"
          ]
        }
      ],
      "source": [
        "def train_lse_model(config_path=\"../configs/training.yaml\"):\n",
        "    print(\"üöÄ Iniciando entrenamiento LSE\")\n",
        "    print(\"=\"*60)\n",
        "    \n",
        "    # Cargar config\n",
        "    with open(config_path, \"r\", encoding=\"utf-8\") as f:\n",
        "        cfg = yaml.safe_load(f)\n",
        "    \n",
        "    model_name = cfg.get(\"model_name\", \"t5-small\")\n",
        "    out_dir = cfg.get(\"output_dir\", \"../runs/exp_cpu_t5s_fixed\")\n",
        "    \n",
        "    train_path = cfg.get(\"train_path\", \"../data/synthetic/train.jsonl\")\n",
        "    dev_path = cfg.get(\"dev_path\", \"../data/synthetic/dev.jsonl\")\n",
        "    test_path = cfg.get(\"test_path\", \"../data/synthetic/test.jsonl\")\n",
        "    \n",
        "    max_src_len = int(cfg.get(\"max_source_length\", 96))\n",
        "    max_tgt_len = int(cfg.get(\"max_target_length\", 64))\n",
        "    \n",
        "    per_device_train_bs = int(cfg.get(\"per_device_train_batch_size\", 8))\n",
        "    per_device_eval_bs = int(cfg.get(\"per_device_eval_batch_size\", 8))\n",
        "    grad_accum_steps = int(cfg.get(\"grad_accum_steps\", 1))\n",
        "    \n",
        "    num_epochs = float(cfg.get(\"num_train_epochs\", 6))\n",
        "    lr = float(cfg.get(\"learning_rate\", 5e-4))\n",
        "    weight_decay = float(cfg.get(\"weight_decay\", 0.01))\n",
        "    warmup_ratio = float(cfg.get(\"warmup_ratio\", 0.05))\n",
        "    logging_steps = int(cfg.get(\"logging_steps\", 100))\n",
        "    \n",
        "    print(f\"ü§ñ Modelo: {model_name}\")\n",
        "    print(f\"üìä √âpocas: {num_epochs}\")\n",
        "    print(f\"üìà LR: {lr}\")\n",
        "    print(\"=\"*60)\n",
        "    \n",
        "    # Cargar tokenizer\n",
        "    print(\"\\nüì¶ Cargando tokenizer...\")\n",
        "    tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "    \n",
        "    spec_path = \"../configs/special_tokens.json\"\n",
        "    if os.path.exists(spec_path):\n",
        "        with open(spec_path, \"r\", encoding=\"utf-8\") as f:\n",
        "            spec = json.load(f)\n",
        "        tokenizer.add_special_tokens(spec)\n",
        "        print(f\"‚úì Tokens especiales: {spec}\")\n",
        "    \n",
        "    model = AutoModelForSeq2SeqLM.from_pretrained(model_name)\n",
        "    model.resize_token_embeddings(len(tokenizer))\n",
        "    \n",
        "    # Cargar datos\n",
        "    print(\"\\nüìö Cargando datasets...\")\n",
        "    ds = build_hf_dataset(train_path, dev_path, test_path)\n",
        "    print(f\"‚úì Train: {len(ds['train'])}\")\n",
        "    print(f\"‚úì Val: {len(ds['validation'])}\")\n",
        "    print(f\"‚úì Test: {len(ds['test'])}\")\n",
        "    \n",
        "    # Preprocesar\n",
        "    def preprocess(batch):\n",
        "        model_inputs = tokenizer(batch[\"src\"], max_length=max_src_len, truncation=True)\n",
        "        labels = tokenizer(text_target=batch[\"tgt\"], max_length=max_tgt_len, truncation=True)\n",
        "        model_inputs[\"labels\"] = labels[\"input_ids\"]\n",
        "        return model_inputs\n",
        "    \n",
        "    print(\"\\nüîÑ Tokenizando...\")\n",
        "    ds_tok = ds.map(preprocess, batched=True, remove_columns=[\"src\", \"tgt\"])\n",
        "    \n",
        "    # Training args\n",
        "    training_args = TrainingArguments(\n",
        "        output_dir=out_dir,\n",
        "        per_device_train_batch_size=per_device_train_bs,\n",
        "        per_device_eval_batch_size=per_device_eval_bs,\n",
        "        learning_rate=lr,\n",
        "        num_train_epochs=num_epochs,\n",
        "        warmup_ratio=warmup_ratio,\n",
        "        weight_decay=weight_decay,\n",
        "        fp16=False,\n",
        "        bf16=False,\n",
        "        gradient_checkpointing=False,\n",
        "        remove_unused_columns=False,\n",
        "        logging_strategy=\"steps\",\n",
        "        logging_steps=logging_steps,\n",
        "        evaluation_strategy=\"epoch\",\n",
        "        save_strategy=\"epoch\",\n",
        "        save_total_limit=2,\n",
        "        report_to=\"none\",\n",
        "        gradient_accumulation_steps=grad_accum_steps,\n",
        "    )\n",
        "    \n",
        "    data_collator = DataCollatorForSeq2Seq(\n",
        "        tokenizer=tokenizer,\n",
        "        model=model,\n",
        "        label_pad_token_id=-100\n",
        "    )\n",
        "    \n",
        "    # Callback\n",
        "    plot_callback = LivePlotCallback()\n",
        "    \n",
        "    # Trainer\n",
        "    trainer = Trainer(\n",
        "        model=model,\n",
        "        args=training_args,\n",
        "        train_dataset=ds_tok[\"train\"],\n",
        "        eval_dataset=ds_tok[\"validation\"],\n",
        "        data_collator=data_collator,\n",
        "        tokenizer=tokenizer,\n",
        "        callbacks=[plot_callback]\n",
        "    )\n",
        "    \n",
        "    # ¬°Entrenar!\n",
        "    print(\"\\nüéØ Entrenando...\")\n",
        "    print(\"=\"*60)\n",
        "    trainer.train()\n",
        "    \n",
        "    # Guardar\n",
        "    print(\"\\nüíæ Guardando...\")\n",
        "    trainer.save_model(out_dir)\n",
        "    tokenizer.save_pretrained(out_dir)\n",
        "    print(f\"‚úÖ Guardado en: {out_dir}\")\n",
        "    \n",
        "    plot_callback.save_final_report(out_dir)\n",
        "    \n",
        "    return trainer, plot_callback\n",
        "\n",
        "print(\"‚úÖ Funci√≥n de entrenamiento creada\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úÖ Funci√≥n de evaluaci√≥n creada\n"
          ]
        }
      ],
      "source": [
        "def evaluate_and_show_examples(trainer, num_examples=10):\n",
        "    import torch\n",
        "    \n",
        "    print(\"\\n\" + \"=\"*60)\n",
        "    print(\"üîç EVALUACI√ìN Y EJEMPLOS\")\n",
        "    print(\"=\"*60)\n",
        "    \n",
        "    results = trainer.evaluate()\n",
        "    \n",
        "    print(\"\\nüìä M√©tricas:\")\n",
        "    for key, value in results.items():\n",
        "        print(f\"   ‚Ä¢ {key}: {value:.4f}\")\n",
        "    \n",
        "    print(f\"\\nüìù Ejemplos de traducci√≥n:\")\n",
        "    print(\"-\"*60)\n",
        "    \n",
        "    tokenizer = trainer.tokenizer\n",
        "    test_samples = trainer.eval_dataset.select(range(min(num_examples, len(trainer.eval_dataset))))\n",
        "    \n",
        "    for i, sample in enumerate(test_samples):\n",
        "        input_ids = sample['input_ids']\n",
        "        input_text = tokenizer.decode(input_ids, skip_special_tokens=True)\n",
        "        \n",
        "        outputs = trainer.model.generate(\n",
        "            input_ids=torch.tensor([input_ids]),\n",
        "            max_length=64,\n",
        "            num_beams=4,\n",
        "            early_stopping=True\n",
        "        )\n",
        "        \n",
        "        prediction = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
        "        reference = tokenizer.decode(sample['labels'], skip_special_tokens=True)\n",
        "        \n",
        "        match = prediction == reference\n",
        "        \n",
        "        print(f\"\\nüîπ Ejemplo {i+1}:\")\n",
        "        print(f\"   üì• Entrada:     {input_text}\")\n",
        "        print(f\"   ‚úÖ Referencia:  {reference}\")\n",
        "        print(f\"   ü§ñ Predicci√≥n:  {prediction}\")\n",
        "        print(f\"   {'‚úì Correcto' if match else '‚úó Diferente'}\")\n",
        "\n",
        "print(\"‚úÖ Funci√≥n de evaluaci√≥n creada\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "üöÄ Iniciando entrenamiento LSE\n",
            "============================================================\n",
            "ü§ñ Modelo: t5-small\n",
            "üìä √âpocas: 6.0\n",
            "üìà LR: 0.0005\n",
            "============================================================\n",
            "\n",
            "üì¶ Cargando tokenizer...\n",
            "‚úì Tokens especiales: {'additional_special_tokens': ['#']}\n",
            "\n",
            "üìö Cargando datasets...\n",
            "‚úì Train: 3000\n",
            "‚úì Val: 400\n",
            "‚úì Test: 400\n",
            "\n",
            "üîÑ Tokenizando...\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "b204c2d4e2694bf88c018e05e64f814e",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Map:   0%|          | 0/3000 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "27f7b506b9a94b438e612f1a58b1659a",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Map:   0%|          | 0/400 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "1d7a9412db144ba5b316514c9b6d3c47",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Map:   0%|          | 0/400 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "ename": "TypeError",
          "evalue": "TrainingArguments.__init__() got an unexpected keyword argument 'evaluation_strategy'",
          "output_type": "error",
          "traceback": [
            "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
            "\u001b[31mTypeError\u001b[39m                                 Traceback (most recent call last)",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[33]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# üöÄ EJECUTAR ENTRENAMIENTO\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m trainer, plot_callback = \u001b[43mtrain_lse_model\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m../configs/training.yaml\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[31]\u001b[39m\u001b[32m, line 66\u001b[39m, in \u001b[36mtrain_lse_model\u001b[39m\u001b[34m(config_path)\u001b[39m\n\u001b[32m     63\u001b[39m ds_tok = ds.map(preprocess, batched=\u001b[38;5;28;01mTrue\u001b[39;00m, remove_columns=[\u001b[33m\"\u001b[39m\u001b[33msrc\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mtgt\u001b[39m\u001b[33m\"\u001b[39m])\n\u001b[32m     65\u001b[39m \u001b[38;5;66;03m# Training args\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m66\u001b[39m training_args = \u001b[43mTrainingArguments\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     67\u001b[39m \u001b[43m    \u001b[49m\u001b[43moutput_dir\u001b[49m\u001b[43m=\u001b[49m\u001b[43mout_dir\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     68\u001b[39m \u001b[43m    \u001b[49m\u001b[43mper_device_train_batch_size\u001b[49m\u001b[43m=\u001b[49m\u001b[43mper_device_train_bs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     69\u001b[39m \u001b[43m    \u001b[49m\u001b[43mper_device_eval_batch_size\u001b[49m\u001b[43m=\u001b[49m\u001b[43mper_device_eval_bs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     70\u001b[39m \u001b[43m    \u001b[49m\u001b[43mlearning_rate\u001b[49m\u001b[43m=\u001b[49m\u001b[43mlr\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     71\u001b[39m \u001b[43m    \u001b[49m\u001b[43mnum_train_epochs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mnum_epochs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     72\u001b[39m \u001b[43m    \u001b[49m\u001b[43mwarmup_ratio\u001b[49m\u001b[43m=\u001b[49m\u001b[43mwarmup_ratio\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     73\u001b[39m \u001b[43m    \u001b[49m\u001b[43mweight_decay\u001b[49m\u001b[43m=\u001b[49m\u001b[43mweight_decay\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     74\u001b[39m \u001b[43m    \u001b[49m\u001b[43mfp16\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m     75\u001b[39m \u001b[43m    \u001b[49m\u001b[43mbf16\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m     76\u001b[39m \u001b[43m    \u001b[49m\u001b[43mgradient_checkpointing\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m     77\u001b[39m \u001b[43m    \u001b[49m\u001b[43mremove_unused_columns\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m     78\u001b[39m \u001b[43m    \u001b[49m\u001b[43mlogging_strategy\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43msteps\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     79\u001b[39m \u001b[43m    \u001b[49m\u001b[43mlogging_steps\u001b[49m\u001b[43m=\u001b[49m\u001b[43mlogging_steps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     80\u001b[39m \u001b[43m    \u001b[49m\u001b[43mevaluation_strategy\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mepoch\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     81\u001b[39m \u001b[43m    \u001b[49m\u001b[43msave_strategy\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mepoch\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     82\u001b[39m \u001b[43m    \u001b[49m\u001b[43msave_total_limit\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m2\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     83\u001b[39m \u001b[43m    \u001b[49m\u001b[43mreport_to\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mnone\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     84\u001b[39m \u001b[43m    \u001b[49m\u001b[43mgradient_accumulation_steps\u001b[49m\u001b[43m=\u001b[49m\u001b[43mgrad_accum_steps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     85\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     87\u001b[39m data_collator = DataCollatorForSeq2Seq(\n\u001b[32m     88\u001b[39m     tokenizer=tokenizer,\n\u001b[32m     89\u001b[39m     model=model,\n\u001b[32m     90\u001b[39m     label_pad_token_id=-\u001b[32m100\u001b[39m\n\u001b[32m     91\u001b[39m )\n\u001b[32m     93\u001b[39m \u001b[38;5;66;03m# Callback\u001b[39;00m\n",
            "\u001b[31mTypeError\u001b[39m: TrainingArguments.__init__() got an unexpected keyword argument 'evaluation_strategy'"
          ]
        }
      ],
      "source": [
        "# üöÄ EJECUTAR ENTRENAMIENTO\n",
        "trainer, plot_callback = train_lse_model(\"../configs/training.yaml\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# üîç EVALUAR Y VER EJEMPLOS\n",
        "evaluate_and_show_examples(trainer, num_examples=10)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## üìä An√°lisis Final\n",
        "\n",
        "### Archivos generados:\n",
        "- `runs/exp_cpu_t5s_fixed/training_report.html` - Gr√°fica interactiva\n",
        "- `runs/exp_cpu_t5s_fixed/training_metrics.csv` - Datos CSV\n",
        "- `runs/exp_cpu_t5s_fixed/` - Modelo entrenado\n",
        "\n",
        "### Pr√≥ximos pasos:\n",
        "1. Revisa el archivo HTML para an√°lisis detallado\n",
        "2. Prueba el modelo con tus propias frases\n",
        "3. Ajusta hiperpar√°metros si es necesario"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}
